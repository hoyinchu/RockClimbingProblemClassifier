{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RockClimbingProblemClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1cm338alFZK",
        "colab_type": "text"
      },
      "source": [
        "Checking our data (one-hot). Make sure one_hot_csv_path is pointing to the file moves_one_hot.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWtYzGXwx8Ce",
        "colab_type": "code",
        "outputId": "8e60cd3e-bda8-4e50-fe3c-fd523e8207e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "one_hot_csv_path = \"/content/drive/My Drive/Colab Notebooks/moves_one_hot.csv\"\n",
        "one_hot_csv_df = pd.read_csv(one_hot_csv_path)\n",
        "one_hot_csv_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>UserRating</th>\n",
              "      <th>Grade</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "      <th>A17</th>\n",
              "      <th>A18</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>B12</th>\n",
              "      <th>B13</th>\n",
              "      <th>B14</th>\n",
              "      <th>B15</th>\n",
              "      <th>B16</th>\n",
              "      <th>B17</th>\n",
              "      <th>B18</th>\n",
              "      <th>C1</th>\n",
              "      <th>...</th>\n",
              "      <th>I15</th>\n",
              "      <th>I16</th>\n",
              "      <th>I17</th>\n",
              "      <th>I18</th>\n",
              "      <th>J1</th>\n",
              "      <th>J2</th>\n",
              "      <th>J3</th>\n",
              "      <th>J4</th>\n",
              "      <th>J5</th>\n",
              "      <th>J6</th>\n",
              "      <th>J7</th>\n",
              "      <th>J8</th>\n",
              "      <th>J9</th>\n",
              "      <th>J10</th>\n",
              "      <th>J11</th>\n",
              "      <th>J12</th>\n",
              "      <th>J13</th>\n",
              "      <th>J14</th>\n",
              "      <th>J15</th>\n",
              "      <th>J16</th>\n",
              "      <th>J17</th>\n",
              "      <th>J18</th>\n",
              "      <th>K1</th>\n",
              "      <th>K2</th>\n",
              "      <th>K3</th>\n",
              "      <th>K4</th>\n",
              "      <th>K5</th>\n",
              "      <th>K6</th>\n",
              "      <th>K7</th>\n",
              "      <th>K8</th>\n",
              "      <th>K9</th>\n",
              "      <th>K10</th>\n",
              "      <th>K11</th>\n",
              "      <th>K12</th>\n",
              "      <th>K13</th>\n",
              "      <th>K14</th>\n",
              "      <th>K15</th>\n",
              "      <th>K16</th>\n",
              "      <th>K17</th>\n",
              "      <th>K18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+TAX</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BELLA CIAO</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PP1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ZICK ZACK</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WE ARE HERE TO TRAIN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Name  UserRating  Grade  A1  A2  ...  K14  K15  K16  K17  K18\n",
              "0                  +TAX           0      6   0   0  ...    0    0    0    0    0\n",
              "1            BELLA CIAO           0      5   0   0  ...    0    0    0    0    0\n",
              "2                   PP1           0      4   0   0  ...    0    0    0    0    0\n",
              "3             ZICK ZACK           0      0   1   0  ...    0    0    0    0    0\n",
              "4  WE ARE HERE TO TRAIN           0      3   0   0  ...    0    0    0    0    0\n",
              "\n",
              "[5 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-O7EEGNGoO1",
        "colab_type": "text"
      },
      "source": [
        "Basic analysis shows our data is skewed toward 6A+ (grade 2), since the imbalance is not too severe we leave it for now. Since there aren't too many samples in classes higher than 7C (grade 11), we assign them to grade 11 to indicate the category \"7C or higher\" To reduce noise, we only take problems with user rating 2 or higher (3 being highest), which leave us with 23861 samples to work with (reduced from 29205)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSc0frImJrXq",
        "colab_type": "code",
        "outputId": "791ae740-22a1-478e-c97e-dc88fe79a045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "one_hot_csv_df = one_hot_csv_df[one_hot_csv_df['UserRating'] >= 2]\n",
        "one_hot_csv_df.loc[one_hot_csv_df['Grade'] > 11, 'Grade'] = 11\n",
        "one_hot_csv_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>UserRating</th>\n",
              "      <th>Grade</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "      <th>A17</th>\n",
              "      <th>A18</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>B10</th>\n",
              "      <th>B11</th>\n",
              "      <th>B12</th>\n",
              "      <th>B13</th>\n",
              "      <th>B14</th>\n",
              "      <th>B15</th>\n",
              "      <th>B16</th>\n",
              "      <th>B17</th>\n",
              "      <th>B18</th>\n",
              "      <th>C1</th>\n",
              "      <th>...</th>\n",
              "      <th>I15</th>\n",
              "      <th>I16</th>\n",
              "      <th>I17</th>\n",
              "      <th>I18</th>\n",
              "      <th>J1</th>\n",
              "      <th>J2</th>\n",
              "      <th>J3</th>\n",
              "      <th>J4</th>\n",
              "      <th>J5</th>\n",
              "      <th>J6</th>\n",
              "      <th>J7</th>\n",
              "      <th>J8</th>\n",
              "      <th>J9</th>\n",
              "      <th>J10</th>\n",
              "      <th>J11</th>\n",
              "      <th>J12</th>\n",
              "      <th>J13</th>\n",
              "      <th>J14</th>\n",
              "      <th>J15</th>\n",
              "      <th>J16</th>\n",
              "      <th>J17</th>\n",
              "      <th>J18</th>\n",
              "      <th>K1</th>\n",
              "      <th>K2</th>\n",
              "      <th>K3</th>\n",
              "      <th>K4</th>\n",
              "      <th>K5</th>\n",
              "      <th>K6</th>\n",
              "      <th>K7</th>\n",
              "      <th>K8</th>\n",
              "      <th>K9</th>\n",
              "      <th>K10</th>\n",
              "      <th>K11</th>\n",
              "      <th>K12</th>\n",
              "      <th>K13</th>\n",
              "      <th>K14</th>\n",
              "      <th>K15</th>\n",
              "      <th>K16</th>\n",
              "      <th>K17</th>\n",
              "      <th>K18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FISCHAA</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SMZ12.1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LOW HANGING MOON JUGS</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SUNSHOT</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MOVE BIC... EPS</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Name  UserRating  Grade  A1  A2  ...  K14  K15  K16  K17  K18\n",
              "6                 FISCHAA           2      2   0   0  ...    0    0    0    0    0\n",
              "7                 SMZ12.1           2      2   0   0  ...    0    0    0    0    0\n",
              "18  LOW HANGING MOON JUGS           2      2   0   0  ...    0    0    0    0    0\n",
              "19                SUNSHOT           3      5   0   0  ...    0    0    0    0    0\n",
              "22        MOVE BIC... EPS           3      2   0   0  ...    0    0    0    0    0\n",
              "\n",
              "[5 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPHe6IzelN8N",
        "colab_type": "text"
      },
      "source": [
        "We split data into training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq0gRob44a3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train and test\n",
        "random_state_seed = 42069\n",
        "target_all = one_hot_csv_df.iloc[:,2].to_numpy()\n",
        "feature_matrix_all = one_hot_csv_df.iloc[:,3:].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix_all, target_all, train_size=0.75, random_state=random_state_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ8Wdoe6APC0",
        "colab_type": "text"
      },
      "source": [
        "Let n be the number of unique classes. To make use of the fact that our target data is ordinal, instead of directly predicting the class label using one multiclass classifier, we train n-1 binary classifiers, where each classifier is responsible for producing the probability of a sample having a grade greater than i, where 0<=i<=n-1. In the end, we can predict the probability of the sample belonging to class y by calculating the difference between the probability of it having a grade greater than y-1 and the probability of it having a grade greater than y. For example, prob(class = 0) = 1 - prob(class>0), prob(class = 4) = prob(class > 3) - prob(class > 4), prob(class = n) = prob(class > n-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THNr4T8R_-cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code reference: https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c\n",
        "from sklearn.base import clone\n",
        "#from copy import deepcopy\n",
        "class OrdinalClassifier():\n",
        "\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.models = {}\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    for i in range(11):\n",
        "      # for each k - 1 ordinal value we fit a binary classification problem\n",
        "      binary_y = (y > i).astype(np.uint8)\n",
        "      model = clone(self.model)\n",
        "      model.fit(X, binary_y)\n",
        "      self.models[i] = model\n",
        "\n",
        "  # Returns a matrix of size 11 x N where N = number of samples  \n",
        "  def predict_proba(self, X):\n",
        "    # models_predict is a dict of prob(y > i) : Nx2 matrix of prob(y<=i),prob(y>i) \n",
        "    models_predict = {i:self.models[i].predict_proba(X) for i in range(len(self.models))}\n",
        "    predicted = []\n",
        "    for i in range(12):\n",
        "        if i == 0:\n",
        "          # V1 = 1 - Pr(y > V1)\n",
        "          predicted.append(1 - models_predict[i][:,1])\n",
        "        elif i != 11:\n",
        "          # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
        "          predicted.append(models_predict[i-1][:,1] - models_predict[i][:,1])\n",
        "        else:\n",
        "          # Vk = Pr(y > Vk-1)\n",
        "          predicted.append(models_predict[i-1][:,1])\n",
        "    return np.vstack(predicted).T\n",
        "    \n",
        "  def predict(self, X):\n",
        "    return np.argmax(self.predict_proba(X), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RScM3rgkekLT",
        "colab_type": "text"
      },
      "source": [
        "Experiment with training with/without the ordinal information. Starting with Naive Bayes. We also define the evaluation metric n-off accuracy, where we consider a prediction to be correct as long as the difference between the actual difficulty and the prediction is within n. For example, (prediction:2, actual: 4) will be considered as a correct prediction in 2-off accuracy but incorrect in 1-off accuracy. We do this to take into account that due to the subjective nature of climbing grades, climbers generally tolerate difficulty level that are 1 level off of what they would expect it to be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21zzH7xW6YeX",
        "colab_type": "code",
        "outputId": "d37e0186-4112-44c0-d5cb-b4e9722cf233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Prediction is considered correct as long as it is within +- n\n",
        "def n_off_accuracy(test,pred,n):\n",
        "  difference = np.absolute(test - pred)\n",
        "  return (difference <= n).sum() / len(test)\n",
        "\n",
        "naive_bayes_model = BernoulliNB()\n",
        "naive_bayes_model.fit(X_train, y_train)\n",
        "naive_bayes_model_prediction = naive_bayes_model.predict(X_test)\n",
        "print(\"Naive Bayes Exact Accuracy: Without Ordinal Classifier\")\n",
        "print(accuracy_score(y_test, naive_bayes_model_prediction))\n",
        "print(\"Naive Bayes 1-off Accuracy: Without Ordinal Classifier\")\n",
        "print(n_off_accuracy(y_test,naive_bayes_model_prediction,1))\n",
        "print(\"Naive Bayes 2-off Accuracy: Without Ordinal Classifier\")\n",
        "print(n_off_accuracy(y_test,naive_bayes_model_prediction,2))\n",
        "print(\"Naive Bayes Test MAE: Without Ordinal Classifier\")\n",
        "print(mean_absolute_error(y_test,naive_bayes_model_prediction))\n",
        "\n",
        "print()\n",
        "\n",
        "naive_bayes_model_ordinal = OrdinalClassifier(BernoulliNB())\n",
        "naive_bayes_model_ordinal.fit(X_train, y_train)\n",
        "naive_bayes_ordinal_prediction = naive_bayes_model_ordinal.predict(X_test)\n",
        "print(\"Naive Bayes Exact Accuracy: With Ordinal Classifier\")\n",
        "print(accuracy_score(y_test, naive_bayes_ordinal_prediction))\n",
        "print(\"Naive Bayes 1-off Accuracy: With Ordinal Classifier\")\n",
        "print(n_off_accuracy(y_test,naive_bayes_ordinal_prediction,1))\n",
        "print(\"Naive Bayes 2-off Accuracy: With Ordinal Classifier\")\n",
        "print(n_off_accuracy(y_test,naive_bayes_ordinal_prediction,2))\n",
        "print(\"Naive Bayes Test MAE: With Ordinal Classifier\")\n",
        "print(mean_absolute_error(y_test,naive_bayes_ordinal_prediction))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Exact Accuracy: Without Ordinal Classifier\n",
            "0.3169627891384512\n",
            "Naive Bayes 1-off Accuracy: Without Ordinal Classifier\n",
            "0.5608447871270533\n",
            "Naive Bayes 2-off Accuracy: Without Ordinal Classifier\n",
            "0.7696949379818974\n",
            "Naive Bayes Test MAE: Without Ordinal Classifier\n",
            "1.5980556486758297\n",
            "\n",
            "Naive Bayes Exact Accuracy: With Ordinal Classifier\n",
            "0.2666778410995642\n",
            "Naive Bayes 1-off Accuracy: With Ordinal Classifier\n",
            "0.4772041568890379\n",
            "Naive Bayes 2-off Accuracy: With Ordinal Classifier\n",
            "0.7252765672142139\n",
            "Naive Bayes Test MAE: With Ordinal Classifier\n",
            "1.8749580958766343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlZIgKnp1mp",
        "colab_type": "text"
      },
      "source": [
        "Using ordinal information does not seem to have added benefits while also increases the training time, we therefore discard this strategy in other models. Next up we attempt using random forest and evaluate it using similar metric. Training takes about 5-10 seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l21UipVWqrdy",
        "colab_type": "code",
        "outputId": "210a13f0-d555-43a7-e0f7-bc6d6ab9650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_model = RandomForestClassifier(random_state=random_state_seed)\n",
        "# Training takes about 5-10 seconds\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "random_forest_model_prediction = random_forest_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Exact Accuracy:\")\n",
        "print(accuracy_score(y_test, random_forest_model_prediction))\n",
        "print(\"Random Forest 1-off Accuracy:\")\n",
        "print(n_off_accuracy(y_test,random_forest_model_prediction,1))\n",
        "print(\"Random Forest 2-off Accuracy:\")\n",
        "print(n_off_accuracy(y_test,random_forest_model_prediction,2))\n",
        "print(\"Random Forest Test MAE:\")\n",
        "print(mean_absolute_error(y_test, random_forest_model_prediction))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Exact Accuracy:\n",
            "0.33791485082132083\n",
            "Random Forest 1-off Accuracy:\n",
            "0.58900435802883\n",
            "Random Forest 2-off Accuracy:\n",
            "0.7955078779751927\n",
            "Random Forest Test MAE:\n",
            "1.4644653033858532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I157PaO8e34y",
        "colab_type": "text"
      },
      "source": [
        "Next up, SVM. Worth noting that our accuracy here is slightly better than the best accuracy in previous work (36.5%) http://cs229.stanford.edu/proj2017/final-reports/5232206.pdf . Training takes about 2-3 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir0Do-kueveW",
        "colab_type": "code",
        "outputId": "becbd8f4-f14c-4268-e68c-f4b0127f4c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(random_state=random_state_seed)\n",
        "svm_model.fit(X_train, y_train)\n",
        "# Training takes about 2-3 minutes\n",
        "svm_model_prediction = svm_model.predict(X_test)\n",
        "print(\"SVM Test Accuracy:\")\n",
        "print(accuracy_score(y_test, svm_model_prediction))\n",
        "print(\"SVM 1-off Accuracy:\")\n",
        "print(n_off_accuracy(y_test,svm_model_prediction,1))\n",
        "print(\"SVM 2-off Accuracy:\")\n",
        "print(n_off_accuracy(y_test,svm_model_prediction,2))\n",
        "print(\"SVM Test MAE:\")\n",
        "print(mean_absolute_error(y_test, svm_model_prediction))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Test Accuracy:\n",
            "0.3672477371773383\n",
            "SVM 1-off Accuracy:\n",
            "0.6101240362051625\n",
            "SVM 2-off Accuracy:\n",
            "0.8183037210861549\n",
            "SVM Test MAE:\n",
            "1.3461280590010056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZXyRu-GoirY",
        "colab_type": "text"
      },
      "source": [
        "Next up, a simple feedforward neural network defined using code from HW4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Tm98ARoeGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "torch.manual_seed(random_state_seed)\n",
        "\n",
        "class HwNet(torch.nn.Module):\n",
        "  def __init__(self, num_layers, units ,final_activation):\n",
        "    super(HwNet, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.final_activation = final_activation\n",
        "    self.units = units\n",
        "    layers = []\n",
        "    for i in range(len(units)-1):\n",
        "      layers.append(torch.nn.Linear(units[i],units[i+1]))\n",
        "    self.layers = torch.nn.ModuleList(layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for i in range(len(self.layers)):\n",
        "      if i == len(self.layers)-1:\n",
        "        if (self.final_activation == \"sigmoid\"):\n",
        "          x = torch.sigmoid(self.layers[i](x))\n",
        "        elif (self.final_activation == \"tanh\"):\n",
        "          x = F.tanh(self.layers[i](x))\n",
        "        elif (self.final_activation == \"relu\"):\n",
        "          x = F.relu(self.layers[i](x))\n",
        "        elif (self.final_activation == \"identity\"):\n",
        "          x = self.layers[i](x)\n",
        "      else:\n",
        "        x = F.relu(self.layers[i](x))\n",
        "    return x\n",
        "\n",
        "  def print_info(self):\n",
        "    print(\"Weights and Biases\")\n",
        "    for param in self.parameters():\n",
        "      print(param.data)\n",
        "    print(\"Final Activation\")\n",
        "    print(self.final_activation)\n",
        "\n",
        "  def train(self,train_data,train_labels):\n",
        "    self.model_reset()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
        "    for t in range(500):\n",
        "      # Forward pass: Compute predicted y by passing x to the model\n",
        "      y_pred = self.forward(train_data)\n",
        "\n",
        "      # Compute and print loss\n",
        "      loss = criterion(y_pred, train_labels)\n",
        "      # if t % 100 == 99:\n",
        "      #     print(t, loss.item())\n",
        "\n",
        "      # Zero gradients, perform a backward pass, and update the weights.\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    # print(\"Training finished\")\n",
        "\n",
        "  def predict(self, x_val):\n",
        "    x = Variable(x_val, requires_grad=False)\n",
        "    output = self.forward(x)\n",
        "    output_numpy = np.argmax(output.data.numpy(), axis=1)\n",
        "    return output_numpy\n",
        "\n",
        "  def model_reset(self):\n",
        "    for layer in self.layers:\n",
        "      layer.reset_parameters()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COW1_JT74LGj",
        "colab_type": "text"
      },
      "source": [
        "Some additional data processing and helper function before feeding into the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dnsLH-8qIpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = torch.from_numpy(X_train).float()\n",
        "testX = torch.from_numpy(X_test).float()\n",
        "trainY = torch.from_numpy(y_train)\n",
        "testY = torch.from_numpy(y_test)\n",
        "\n",
        "def evaluate_model(model,trainX,trainY,testX,testY):\n",
        "  model.train(trainX,trainY)\n",
        "  model_prediction_test = model.predict(testX)\n",
        "  model_test_accuracy = accuracy_score(model_prediction_test,testY.data.numpy())\n",
        "  model_1_off_accuracy = n_off_accuracy(model_prediction_test,testY.data.numpy(),1)\n",
        "  model_2_off_accuracy = n_off_accuracy(model_prediction_test,testY.data.numpy(),2)\n",
        "  model_mae = mean_absolute_error(model_prediction_test, testY.data.numpy())\n",
        "  return model_test_accuracy,model_1_off_accuracy,model_2_off_accuracy,model_mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5JYDFOz4QmL",
        "colab_type": "text"
      },
      "source": [
        "Train and evaluate the neural network. This takes about 5-6 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGXVK7QZrRU-",
        "colab_type": "code",
        "outputId": "5ec6ae14-9a2f-4fc9-c4bb-5e5652752b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import time\n",
        "# Experiment with different neurons in different layers\n",
        "# There are 11*18 = 198 features\n",
        "# Training takes about 5-6 minutes\n",
        "model_2_512_sig = HwNet(4, [198,512,512,12],'sigmoid')\n",
        "model_test_accuracy,model_1_off_accuracy,model_2_off_accuracy,model_mae = evaluate_model(model_2_512_sig,trainX,trainY,testX,testY)\n",
        "print(\"Linear NN 198-512-512-12 Accuracy:\")\n",
        "print(model_test_accuracy)\n",
        "print(\"Linear NN 198-512-512-12 1-off Accuracy:\")\n",
        "print(model_1_off_accuracy)\n",
        "print(\"Linear NN 198-512-512-12 2-off Accuracy:\")\n",
        "print(model_2_off_accuracy)\n",
        "print(\"Linear NN 198-512-512-12 Test MAE:\")\n",
        "print(model_mae)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear NN 198-512-512-12 Accuracy:\n",
            "0.26952732148843445\n",
            "Linear NN 198-512-512-12 1-off Accuracy:\n",
            "0.3984244049614482\n",
            "Linear NN 198-512-512-12 2-off Accuracy:\n",
            "0.5636942675159236\n",
            "Linear NN 198-512-512-12 Test MAE:\n",
            "2.7346630908481395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6goQN-UKrBU",
        "colab_type": "text"
      },
      "source": [
        "The result of using one hot vector is not too satisfactory, let's see if that changes when we treat the problem as a natural language problem. Make sure moves_reordered_compact_path points to the file moves_reordered_path.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLoDoN3GKlE_",
        "colab_type": "code",
        "outputId": "f38fe729-eed2-4031-a559-be15b5c92701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Checking our data and filtering it the same way we did before\n",
        "moves_reordered_compact_path = \"/content/drive/My Drive/Colab Notebooks/moves_reordered_compact.csv\"\n",
        "moves_reordered_df = pd.read_csv(moves_reordered_compact_path)\n",
        "moves_reordered_df = moves_reordered_df[moves_reordered_df['UserRating'] >= 2]\n",
        "moves_reordered_df.loc[moves_reordered_df['Grade'] > 11, 'Grade'] = 11\n",
        "moves_reordered_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>UserRating</th>\n",
              "      <th>Holds</th>\n",
              "      <th>Grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FISCHAA</td>\n",
              "      <td>2</td>\n",
              "      <td>H5 E3 F8 I7 J11 D10 E13 A14 C16 B18 E18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SMZ12.1</td>\n",
              "      <td>2</td>\n",
              "      <td>D5 F5 F8 I8 I7 H10 F12 D12 E13 D15 C16 D9 F18 B18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LOW HANGING MOON JUGS</td>\n",
              "      <td>2</td>\n",
              "      <td>J1 F5 I8 F11 F12 D15 H15 F18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SUNSHOT</td>\n",
              "      <td>3</td>\n",
              "      <td>G6 K5 G8 D9 C13 F13 D15 B18</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MOVE BIC... EPS</td>\n",
              "      <td>3</td>\n",
              "      <td>F5 H5 I8 H10 G13 E13 H16 F18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Name  ...  Grade\n",
              "6                 FISCHAA  ...      2\n",
              "7                 SMZ12.1  ...      2\n",
              "18  LOW HANGING MOON JUGS  ...      2\n",
              "19                SUNSHOT  ...      5\n",
              "22        MOVE BIC... EPS  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZufKHYhw_UK",
        "colab_type": "text"
      },
      "source": [
        "To make use of pytorch nlp capabilities, we convert the data to json line format for easier processing. Running this code wll generate train.json and test.json. If train.json and test.json already exist there is no need to run this block of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWj0V1qxJ0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "feature_matrix_all = moves_reordered_df.loc[:, ['Holds']].to_numpy()\n",
        "target_all = moves_reordered_df.loc[:, ['Grade']].to_numpy()\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(feature_matrix_all, target_all, train_size=0.75, random_state=random_state_seed)\n",
        "\n",
        "with open('train.json', 'w') as outfile:\n",
        "  for pair in zip(X_train_2,y_train_2):\n",
        "    row = {}\n",
        "    holds = pair[0].item(0).split(' ')\n",
        "    grade = pair[1].item(0)\n",
        "    row['Holds'] = holds\n",
        "    row['Grade'] = grade\n",
        "    json.dump(row, outfile)\n",
        "    outfile.write('\\n')\n",
        "\n",
        "with open('test.json', 'w') as outfile:\n",
        "  for pair in zip(X_test_2,y_test_2):\n",
        "    row = {}\n",
        "    holds = pair[0].item(0).split(' ')\n",
        "    grade = pair[1].item(0)\n",
        "    row['Holds'] = holds\n",
        "    row['Grade'] = grade\n",
        "    json.dump(row, outfile)\n",
        "    outfile.write('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6MPUgwyQemw",
        "colab_type": "text"
      },
      "source": [
        "We first load up the data in a format that is compatible with torchtext and split them into train, validation, and test. We also set up some miscellaneous settings that will help us train the neural network. Make sure the train_test_data_directory is pointing to the directory containing train.json and test.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW3-kIoRdHVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_test_data_directory = '/content/drive/My Drive/Colab Notebooks'\n",
        "HOLDS = data.Field()\n",
        "GRADE = data.LabelField()\n",
        "fields = {'Holds': ('holds', HOLDS), 'Grade': ('grade', GRADE)}\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                            path = train_test_data_directory,\n",
        "                            train = 'train.json',\n",
        "                            test = 'test.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(random_state_seed))\n",
        "\n",
        "HOLDS.build_vocab(train_data)\n",
        "GRADE.build_vocab(train_data)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qTXRieXfuuT",
        "colab_type": "text"
      },
      "source": [
        "We define a CNN model that can be used on sequences.\n",
        "Code Rederence:https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuW1NIf_Qqll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "               dropout, pad_idx):\n",
        "    super().__init__()     \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1, \n",
        "                                          out_channels = n_filters, \n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes\n",
        "                                ])\n",
        "        \n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)   \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "  def forward(self, text):\n",
        "    #text = [sent len, batch size]        \n",
        "    text = text.permute(1, 0)                \n",
        "    #text = [batch size, sent len]       \n",
        "    embedded = self.embedding(text)               \n",
        "    #embedded = [batch size, sent len, emb dim]      \n",
        "    embedded = embedded.unsqueeze(1)      \n",
        "    #embedded = [batch size, 1, sent len, emb dim]\n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "    #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    #pooled_n = [batch size, n_filters]\n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvQHmVGI-H0B",
        "colab_type": "text"
      },
      "source": [
        "Defining helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJpUaztv9k9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "  max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "  correct = max_preds.squeeze(1).eq(y)\n",
        "  return correct.sum() / torch.FloatTensor([y.shape[0]])\n",
        "\n",
        "def train(model, iterator, criterion, parameters):\n",
        "  optimizer = optim.Adam(model.parameters(),lr=parameters['lr'])\n",
        "  #optimizer = optim.SGD(model.parameters(),lr=parameters['lr'])\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.holds)\n",
        "    loss = criterion(predictions, batch.grade)\n",
        "    acc = categorical_accuracy(predictions, batch.grade)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator), model\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  epoch_1_off_acc = 0\n",
        "  epoch_2_off_acc = 0\n",
        "  epoch_mae = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.holds)\n",
        "      loss = criterion(predictions, batch.grade)\n",
        "      acc = categorical_accuracy(predictions, batch.grade)\n",
        "      epoch_1_off_acc += n_off_accuracy(np.argmax(predictions.data.numpy(), axis=1),batch.grade.data.numpy(),1)\n",
        "      epoch_2_off_acc += n_off_accuracy(np.argmax(predictions.data.numpy(), axis=1),batch.grade.data.numpy(),2)\n",
        "      epoch_mae += mean_absolute_error(np.argmax(predictions.data.numpy(), axis=1), batch.grade.data.numpy())\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_1_off_acc / len(iterator), epoch_2_off_acc / len(iterator),epoch_mae / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1UM_ndXHyIM",
        "colab_type": "text"
      },
      "source": [
        "Install Bayesian Optimization dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uiOPULJHvld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install ax-platform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62-PykE5rfJs",
        "colab_type": "text"
      },
      "source": [
        "Define model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8_j_eMFrWGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ax.service.managed_loop import optimize\n",
        "\n",
        "INPUT_DIM = len(HOLDS.vocab)\n",
        "# EMBEDDING_DIM = 10\n",
        "# N_FILTERS = 100\n",
        "# DROPOUT = 0.5\n",
        "# LR = 0.1 on adam\n",
        "FILTER_SIZES = [2,3,4]\n",
        "OUTPUT_DIM = len(GRADE.vocab)\n",
        "PAD_IDX = HOLDS.vocab.stoi[HOLDS.pad_token]\n",
        "\n",
        "def train_evaluate(parameterization):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  criterion = criterion.to(device)\n",
        "  model = CNN(INPUT_DIM, round(parameterization['embedding']), round(parameterization['filters']), FILTER_SIZES, OUTPUT_DIM, parameterization['dropout'], PAD_IDX)\n",
        "  model = model.to(device)\n",
        "  _,_,net = train(model=model, iterator=train_iterator,criterion=criterion, parameters=parameterization)\n",
        "  valid_loss,_,_,_,_ = evaluate(model=net,iterator=valid_iterator,criterion=criterion)\n",
        "  return valid_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvjEPQ3X-WgX",
        "colab_type": "text"
      },
      "source": [
        "Finding the best hyperparameters for the model and saves the result model. Takes about 1-2 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZiilWJ5-WRP",
        "colab_type": "code",
        "outputId": "1172a4bf-4ca7-4c69-e69e-26d6345d9f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "best_parameters, values, _, _ = optimize(\n",
        "    parameters=[\n",
        "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
        "        {\"name\": \"dropout\", \"type\": \"range\", \"bounds\": [0.2, 0.6]},\n",
        "        {\"name\": \"embedding\", \"type\": \"range\", \"bounds\": [1,300]},\n",
        "        {\"name\": \"filters\", \"type\": \"range\", \"bounds\":[1,200]}\n",
        "    ],\n",
        "    evaluation_function=train_evaluate,\n",
        "    minimize=True\n",
        ")\n",
        "\n",
        "print(best_parameters)\n",
        "print(values)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 04-24 00:56:37] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 arms, GPEI for subsequent arms], generated 0 arm(s) so far). Iterations after 5 will take longer to generate due to model-fitting.\n",
            "[INFO 04-24 00:56:37] ax.service.managed_loop: Started full optimization with 20 steps.\n",
            "[INFO 04-24 00:56:37] ax.service.managed_loop: Running optimization trial 1...\n",
            "[INFO 04-24 00:56:45] ax.service.managed_loop: Running optimization trial 2...\n",
            "[INFO 04-24 00:56:52] ax.service.managed_loop: Running optimization trial 3...\n",
            "[INFO 04-24 00:56:56] ax.service.managed_loop: Running optimization trial 4...\n",
            "[INFO 04-24 00:57:00] ax.service.managed_loop: Running optimization trial 5...\n",
            "[INFO 04-24 00:57:22] ax.service.managed_loop: Running optimization trial 6...\n",
            "[INFO 04-24 00:57:35] ax.service.managed_loop: Running optimization trial 7...\n",
            "[INFO 04-24 00:57:42] ax.service.managed_loop: Running optimization trial 8...\n",
            "[INFO 04-24 00:57:51] ax.service.managed_loop: Running optimization trial 9...\n",
            "[INFO 04-24 00:58:01] ax.service.managed_loop: Running optimization trial 10...\n",
            "[INFO 04-24 00:58:17] ax.service.managed_loop: Running optimization trial 11...\n",
            "[INFO 04-24 00:58:31] ax.service.managed_loop: Running optimization trial 12...\n",
            "[INFO 04-24 00:58:49] ax.service.managed_loop: Running optimization trial 13...\n",
            "[INFO 04-24 00:59:03] ax.service.managed_loop: Running optimization trial 14...\n",
            "[INFO 04-24 00:59:22] ax.service.managed_loop: Running optimization trial 15...\n",
            "[INFO 04-24 00:59:37] ax.service.managed_loop: Running optimization trial 16...\n",
            "[INFO 04-24 00:59:55] ax.service.managed_loop: Running optimization trial 17...\n",
            "[INFO 04-24 01:00:01] ax.service.managed_loop: Running optimization trial 18...\n",
            "[INFO 04-24 01:00:22] ax.service.managed_loop: Running optimization trial 19...\n",
            "[INFO 04-24 01:00:42] ax.service.managed_loop: Running optimization trial 20...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.0011613296155845206, 'dropout': 0.4068616587758692, 'embedding': 117, 'filters': 168}\n",
            "({'objective': 1.82704477985812}, {'objective': {'objective': 2.458726097556533e-09}})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1d5_JV4V-KF",
        "colab_type": "text"
      },
      "source": [
        "Train model with these parameters and save the model that does best on valdiation set from 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdAuSL2EV5F6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ccdb2322-56b1-40a6-cecf-ed4df264cbdb"
      },
      "source": [
        "from decimal import Decimal\n",
        "\n",
        "best_lr = best_parameters['lr']\n",
        "best_dropout = best_parameters['dropout']\n",
        "best_embedding_dimension = best_parameters['embedding']\n",
        "best_filter_nums = best_parameters['filters']\n",
        "best_lr_decimal = round(Decimal(best_lr),4)\n",
        "best_dropout_decimal = round(Decimal(best_dropout),4)\n",
        "\n",
        "best_model = CNN(INPUT_DIM, best_embedding_dimension, best_filter_nums, FILTER_SIZES, OUTPUT_DIM, best_dropout, PAD_IDX)\n",
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc, _ = train(best_model, train_iterator,criterion,best_parameters)\n",
        "    valid_loss, valid_acc,model_1_off_accuracy,model_2_off_accuracy,model_mae = evaluate(best_model, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(best_model.state_dict(), f'loss-{best_valid_loss:.3f}-eb-{best_embedding_dimension}-ft-{best_filter_nums}-lr-{best_lr_decimal}-do-{best_dropout_decimal}.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 2.010 | Train Acc: 30.01%\n",
            "\t Val. Loss: 1.848 |  Val. Acc: 33.22%\n",
            "Epoch: 02 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 1.815 | Train Acc: 35.19%\n",
            "\t Val. Loss: 1.818 |  Val. Acc: 35.01%\n",
            "Epoch: 03 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 1.718 | Train Acc: 38.11%\n",
            "\t Val. Loss: 1.857 |  Val. Acc: 34.22%\n",
            "Epoch: 04 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 1.640 | Train Acc: 41.35%\n",
            "\t Val. Loss: 1.860 |  Val. Acc: 34.63%\n",
            "Epoch: 05 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 1.558 | Train Acc: 43.98%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 32.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_hmQsP7LehN",
        "colab_type": "text"
      },
      "source": [
        "Test the model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OsS-o72LeLN",
        "colab_type": "code",
        "outputId": "5bc9d5eb-0e71-444c-95f1-bb04afb62d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "best_model = CNN(INPUT_DIM, best_embedding_dimension, best_filter_nums, FILTER_SIZES, OUTPUT_DIM, best_dropout, PAD_IDX)\n",
        "best_model.load_state_dict(torch.load(f'loss-{best_valid_loss:.3f}-eb-{best_embedding_dimension}-ft-{best_filter_nums}-lr-{best_lr_decimal}-do-{best_dropout_decimal}.pt'))\n",
        "test_loss, test_acc, model_1_off_accuracy,model_2_off_accuracy, model_mae = evaluate(best_model, test_iterator, criterion)\n",
        "\n",
        "print(\"CNN Exact Accuracy:\")\n",
        "print(test_acc)\n",
        "print(\"CNN 1-off Accuracy:\")\n",
        "print(model_1_off_accuracy)\n",
        "print(\"CNN 2-off Accuracy:\")\n",
        "print(model_2_off_accuracy)\n",
        "print(\"CNN Test MAE:\")\n",
        "print(model_mae)\n",
        "\n",
        "#print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Exact Accuracy:\n",
            "0.3459821429024351\n",
            "CNN 1-off Accuracy:\n",
            "0.5635210866261399\n",
            "CNN 2-off Accuracy:\n",
            "0.7385068389057751\n",
            "CNN Test MAE:\n",
            "1.8363174392097263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "182UpQ9IhFJJ",
        "colab_type": "text"
      },
      "source": [
        "As a baseline comparison, we create a FastText model used in \"Bag of Tricks for Efficient Text Classification\" https://arxiv.org/abs/1607.01759 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0klS0ApGDJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FastText(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):  \n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "    self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "    #text = [sent len, batch size]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded = [sent len, batch size, emb dim]\n",
        "    embedded = embedded.permute(1, 0, 2)\n",
        "    #embedded = [batch size, sent len, emb dim]\n",
        "    pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
        "    #pooled = [batch size, embedding_dim]\n",
        "    return self.fc(pooled)\n",
        "\n",
        "model = FastText(INPUT_DIM, best_embedding_dimension, OUTPUT_DIM, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiMoA0lfGxxv",
        "colab_type": "text"
      },
      "source": [
        "Training FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp-4moVQGxlM",
        "colab_type": "code",
        "outputId": "00ae94bc-2473-4377-ad5c-ef3e29b5c80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc, _ = train(model, train_iterator, criterion, best_parameters)\n",
        "    vvalid_loss, valid_acc,model_1_off_accuracy,model_2_off_accuracy,model_mae = evaluate(model, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'fast-text-model.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.144 | Train Acc: 27.90%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 29.85%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 32.03%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 31.88%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.877 | Train Acc: 33.53%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 32.87%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.847 | Train Acc: 33.96%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 32.95%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.828 | Train Acc: 34.64%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 33.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Tz3BDULXO5",
        "colab_type": "text"
      },
      "source": [
        "Finally test fasttext on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-zXX8JALZTQ",
        "colab_type": "code",
        "outputId": "4830e308-c096-40ca-eb3e-7c3b2167c834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "model.load_state_dict(torch.load('fast-text-model.pt'))\n",
        "test_loss, test_acc, model_1_off_accuracy,model_2_off_accuracy, model_mae = evaluate(model, test_iterator, criterion)\n",
        "print(\"FastText Exact Accuracy:\")\n",
        "print(test_acc)\n",
        "print(\"FastText 1-off Accuracy:\")\n",
        "print(model_1_off_accuracy)\n",
        "print(\"FastText 2-off Accuracy:\")\n",
        "print(model_2_off_accuracy)\n",
        "print(\"FastText Test MAE:\")\n",
        "print(model_mae)\n",
        "#print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText Exact Accuracy:\n",
            "0.2959014058430144\n",
            "FastText 1-off Accuracy:\n",
            "0.4549297112462006\n",
            "FastText 2-off Accuracy:\n",
            "0.6078077507598784\n",
            "FastText Test MAE:\n",
            "2.516337386018237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe1Jav52KEXE",
        "colab_type": "text"
      },
      "source": [
        "To test the statistical significance of our result, we compare them against a dummy model that generates predictions using the same distribution as the training set’s class distribution and a SVM model that only uses the number of holds in a problem as the feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1wXFpAQjQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5c6fa101-b1a9-4c38-ecd8-abe1d500b734"
      },
      "source": [
        "X_train_num_moves = X_train.sum(axis=1).reshape(-1, 1)\n",
        "X_test_num_moves = X_test.sum(axis=1).reshape(-1, 1)\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"stratified\",random_state=random_state_seed,constant=2)\n",
        "dummy_clf.fit(X_train_num_moves, y_train)\n",
        "dummy_clf_predictions = dummy_clf.predict(X_test_num_moves)\n",
        "print(\"Dummy Exact Accuracy (stratified):\")\n",
        "print(accuracy_score(y_test, dummy_clf_predictions))\n",
        "print(\"Dummy 1-off Accuracy (stratified):\")\n",
        "print(n_off_accuracy(y_test,dummy_clf_predictions,1))\n",
        "print(\"Dummy 2-off Accuracy (stratified):\")\n",
        "print(n_off_accuracy(y_test,dummy_clf_predictions,2))\n",
        "print(\"Dummy Test MAE (stratified):\")\n",
        "print(mean_absolute_error(y_test, dummy_clf_predictions))\n",
        "\n",
        "print()\n",
        "\n",
        "svm_model = SVC(random_state=random_state_seed)\n",
        "svm_model.fit(X_train_num_moves, y_train)\n",
        "# Training takes about 10-20 seconds\n",
        "svm_model_prediction = svm_model.predict(X_test_num_moves)\n",
        "print(\"SVM Eaxct Accuracy (using number of moves only):\")\n",
        "print(accuracy_score(y_test, svm_model_prediction))\n",
        "print(\"SVM 1-off Accuracy (using number of moves only):\")\n",
        "print(n_off_accuracy(y_test,svm_model_prediction,1))\n",
        "print(\"SVM 2-off Accuracy (using number of moves only):\")\n",
        "print(n_off_accuracy(y_test,svm_model_prediction,2))\n",
        "print(\"SVM Test MAE (using number of moves only):\")\n",
        "print(mean_absolute_error(y_test, svm_model_prediction))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy Exact Accuracy (stratified):\n",
            "0.13476366074421722\n",
            "Dummy 1-off Accuracy (stratified):\n",
            "0.30958766342608113\n",
            "Dummy 2-off Accuracy (stratified):\n",
            "0.4927924907810929\n",
            "Dummy Test MAE (stratified):\n",
            "3.0424069728461283\n",
            "\n",
            "SVM Eaxct Accuracy (using number of moves only):\n",
            "0.2696949379818974\n",
            "SVM 1-off Accuracy (using number of moves only):\n",
            "0.4054642976868924\n",
            "SVM 2-off Accuracy (using number of moves only):\n",
            "0.5714046262152196\n",
            "SVM Test MAE (using number of moves only):\n",
            "2.659068052296346\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}